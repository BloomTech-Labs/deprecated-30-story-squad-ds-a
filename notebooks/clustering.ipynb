{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clustering For Match Making"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Remainder Problem\n",
    "Instead of being left with 1 user who gets grouped with 3 bots, make the last three groups all have 3 users and 1 bot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Clustering algorithms\n",
    "Split based on ranked squad_score: Simpliest mvp\n",
    "- ended up implementing this method due to time constrants. The other methods involve utilizing all of the metrics which invloved setting up a DS database which we dodn't have implemented at this time.\n",
    "\n",
    "K Means: Doesn't split into even groups like we need, cluster into 5 similar tiers and then group within each cluster based off of Squad Score.\n",
    "\n",
    "KNN: Select a random user, grab the 3 closest neighbors, repeat until everyone is matched\n",
    "\n",
    "Agglomarative clustering: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "linear sum assignment: https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.linear_sum_assignment.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   story_id  story_length  avg_word_len  quotes_num  unique_words_num  \\\n",
       "0      3132          1375      5.092593           6               138   \n",
       "1      3104           903      4.961538           0               110   \n",
       "2      3103           750      5.000000           1                93   \n",
       "3      3117           439      4.877778           1                56   \n",
       "4      3102          1812      4.897297           0               193   \n",
       "\n",
       "   adj_num  squad_score  \n",
       "0       15    47.843668  \n",
       "1       12    32.839743  \n",
       "2       10    29.830446  \n",
       "3        3    17.120997  \n",
       "4       22    54.416686  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story_length</th>\n      <th>avg_word_len</th>\n      <th>quotes_num</th>\n      <th>unique_words_num</th>\n      <th>adj_num</th>\n      <th>squad_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3132</td>\n      <td>1375</td>\n      <td>5.092593</td>\n      <td>6</td>\n      <td>138</td>\n      <td>15</td>\n      <td>47.843668</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3104</td>\n      <td>903</td>\n      <td>4.961538</td>\n      <td>0</td>\n      <td>110</td>\n      <td>12</td>\n      <td>32.839743</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3103</td>\n      <td>750</td>\n      <td>5.000000</td>\n      <td>1</td>\n      <td>93</td>\n      <td>10</td>\n      <td>29.830446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3117</td>\n      <td>439</td>\n      <td>4.877778</td>\n      <td>1</td>\n      <td>56</td>\n      <td>3</td>\n      <td>17.120997</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3102</td>\n      <td>1812</td>\n      <td>4.897297</td>\n      <td>0</td>\n      <td>193</td>\n      <td>22</td>\n      <td>54.416686</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read in metrics csv\n",
    "df = pd.read_csv('../data/squad_score_metrics.csv', index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "### Using K Means Clustering\n",
    "- Segment the users into different clusters based on all of the metrics - 5 'tiers'\n",
    "- Within their clusters, group into groups of 4 based on their Squad Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   story_id  story_length  avg_word_len  quotes_num  unique_words_num  \\\n",
       "0      3132          1375      5.092593           6               138   \n",
       "1      3104           903      4.961538           0               110   \n",
       "2      3103           750      5.000000           1                93   \n",
       "3      3117           439      4.877778           1                56   \n",
       "4      3102          1812      4.897297           0               193   \n",
       "\n",
       "   adj_num  squad_score  cluster  \n",
       "0       15    47.843668        0  \n",
       "1       12    32.839743        2  \n",
       "2       10    29.830446        2  \n",
       "3        3    17.120997        2  \n",
       "4       22    54.416686        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story_length</th>\n      <th>avg_word_len</th>\n      <th>quotes_num</th>\n      <th>unique_words_num</th>\n      <th>adj_num</th>\n      <th>squad_score</th>\n      <th>cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3132</td>\n      <td>1375</td>\n      <td>5.092593</td>\n      <td>6</td>\n      <td>138</td>\n      <td>15</td>\n      <td>47.843668</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3104</td>\n      <td>903</td>\n      <td>4.961538</td>\n      <td>0</td>\n      <td>110</td>\n      <td>12</td>\n      <td>32.839743</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3103</td>\n      <td>750</td>\n      <td>5.000000</td>\n      <td>1</td>\n      <td>93</td>\n      <td>10</td>\n      <td>29.830446</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3117</td>\n      <td>439</td>\n      <td>4.877778</td>\n      <td>1</td>\n      <td>56</td>\n      <td>3</td>\n      <td>17.120997</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3102</td>\n      <td>1812</td>\n      <td>4.897297</td>\n      <td>0</td>\n      <td>193</td>\n      <td>22</td>\n      <td>54.416686</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Get clusters\n",
    "\n",
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Pull out features\n",
    "features = df.drop('story_id', axis=1)\n",
    "\n",
    "# Scale data\n",
    "norm_x = scaler.fit_transform(features)\n",
    "\n",
    "# Instantiate model - 5 clusters\n",
    "model= KMeans(n_clusters = 5)\n",
    "\n",
    "# Predict clusters\n",
    "df['cluster'] = model.fit_predict(norm_x)\n",
    "\n",
    "# View df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    44\n",
       "2    44\n",
       "3    39\n",
       "1    26\n",
       "4    14\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Cluster distribution\n",
    "df['cluster'].value_counts()"
   ]
  },
  {
   "source": [
    "The associated number of the clusters change each time you run the model, but the distribution remains the exact same"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# MVP Clustering from Squad Scores\n",
    "\n",
    "Grouping function:\n",
    "- uses the remainder from len(df) % 4 to make decisions of how to group the last users\n",
    "- edge case conditions handles if there are less than 6 users, otherwise it would return some keys with blank values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_4(df):\n",
    "    '''\n",
    "    Function to split given dataframe into groups of 4 based on their ranked squad_scores\n",
    "    When there is a remainder of users not evenly divisable by 4, it will split the remainder so there is never more than 1 computer user in a group, unless there are less that 3 users.\n",
    "\n",
    "        Input: df to be grouped containing the column 'squad_score' and 'story_id'\n",
    "        Output: Dictionary of groupings. {group #: list of story_id's}\n",
    "\n",
    "    '''\n",
    "    # Rank by squad_score\n",
    "    df = df.sort_values(by= ['squad_score'], ascending= False)\n",
    "\n",
    "    # Initial variables\n",
    "    split = len(df) // 4\n",
    "    remainder = len(df) % 4\n",
    "    group_dict = {}\n",
    "\n",
    "    # Edge Cases: \n",
    "    # - less than 4, they are all in one group\n",
    "    # - 5, one group of 3 one group of 2\n",
    "    if len(df) == 5:\n",
    "        group_dict[1] = list(df['story_id'][:3])\n",
    "        group_dict[2] = list(df['story_id'][3:])\n",
    "        return group_dict\n",
    "    \n",
    "    if len(df) < 4:\n",
    "        group_dict[1] = list(df['story_id'][:])\n",
    "        return group_dict\n",
    "\n",
    "    # If the remainder is 3 -> last group will be a group of 3 users\n",
    "    if remainder == 3:\n",
    "        for i in range(split):\n",
    "            # Group by top 4 squad scores\n",
    "            group_dict[i+1] = list(df['story_id'][:4])\n",
    "            # Drop stories you have grouped already \n",
    "            df = df[4:]\n",
    "        \n",
    "        # Final group is the last 3 remainders\n",
    "        group_dict[split +1] = list(df['story_id'][:])\n",
    "        return group_dict\n",
    "\n",
    "    # If the remainder is 2 -> last 2 groups will be groups of 3\n",
    "    elif remainder == 2:\n",
    "        # Leave the last 2 groups to split into 2 groups of 3\n",
    "        for i in range(split -1):\n",
    "            # Group by top 4 squad scores\n",
    "            group_dict[i+1] = list(df['story_id'][:4])\n",
    "            # Drop stories you have grouped already\n",
    "            df = df[4:]\n",
    "\n",
    "        # The last two groups will be groups of 3\n",
    "        group_dict[split] = list(df['story_id'][:3])\n",
    "        group_dict[split + 1] = list(df['story_id'][3:])\n",
    "        return group_dict\n",
    "\n",
    "    # If the remainder is 1 -> last 3 groups will be groups of 3\n",
    "    elif remainder == 1:\n",
    "        # Leave the last 3 groups to be split into 3 groups of 3\n",
    "        for i in range(split -2):\n",
    "            # Group by top 4 squad scores\n",
    "            group_dict[i+1] = list(df['story_id'][:4])\n",
    "            # Drop stories you have already grouped\n",
    "            df = df[4:]\n",
    "\n",
    "        # The last three groups as groups of 3\n",
    "        group_dict[split -1] = list(df['story_id'][:3])\n",
    "        group_dict[split] = list(df['story_id'][3:6])\n",
    "        group_dict[split + 1] = list(df['story_id'][6:])\n",
    "        return group_dict\n",
    "    \n",
    "    # If the remainder is 0, split evenly by 4\n",
    "    elif remainder == 0:\n",
    "        for i in range(split):\n",
    "            # Group by top 4 squad scores\n",
    "            group_dict[i+1] = list(df['story_id'][:4])\n",
    "            # Drop stories you have already grouped\n",
    "            df = df[4:]\n",
    "        return group_dict\n",
    "\n",
    "    else:\n",
    "        return 'Invalid number of remaining users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each cluster 'tier'\n",
    "first = df[df['cluster']== 0]\n",
    "second = df[df['cluster']== 1]\n",
    "third = df[df['cluster']== 2]\n",
    "fourth = df[df['cluster']== 3]\n",
    "fifth = df[df['cluster']== 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the cluster dictionaries\n",
    "first_cluster = group_4(first)\n",
    "second_cluster = group_4(second)\n",
    "third_cluster = group_4(third)\n",
    "fourth_cluster = group_4(fourth)\n",
    "fifth_cluster = group_4(fifth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First Cluster: {1: [5105, 5217, 3115, 5251], 2: [5113, 5237, 5125, 3102], 3: [5218, 5255, 3219, 5204], 4: [5121, 5202, 5259, 3204], 5: [5263, 5210, 5203, 3122], 6: [3109, 5246, 3213, 3239], 7: [5114, 3132, 3224, 5108], 8: [3101, 5228, 3114, 3211], 9: [3217, 5225, 3220, 5249], 10: [5239, 3232, 5260, 3216], 11: [5240, 5102, 5229, 3247]}\nSecond Cluster: {1: [5219, 5117, 5119, 5107], 2: [5118, 5222, 5215, 5227], 3: [5124, 5106, 5129, 5224], 4: [3130, 3209, 5247, 5252], 5: [5206, 3230, 5248, 5131], 6: [5262, 5111, 5253], 7: [5208, 5257, 5261]}\nThird Cluster: {1: [5209, 5221, 3118, 5243], 2: [3215, 3210, 5123, 5232], 3: [3227, 3128, 3223, 3123], 4: [5120, 3116, 5207, 3104], 5: [5258, 3111, 3225, 5214], 6: [3226, 3103, 3238, 3206], 7: [3207, 3125, 3113, 3107], 8: [3222, 5110, 3124, 3235], 9: [3131, 3119, 3236, 5233], 10: [3121, 3214, 3110, 3127], 11: [3202, 3117, 3240, 3229]}\nFourth Cluster: {1: [5122, 5230, 5244, 3221], 2: [3234, 5132, 3246, 3129], 3: [5115, 5126, 3245, 5238], 4: [5112, 3243, 3248, 3237], 5: [3208, 5101, 3203, 3218], 6: [5256, 5216, 5264, 5103], 7: [3112, 3105, 3241, 3126], 8: [5116, 3244, 3205, 5104], 9: [5109, 3231, 3120, 3201], 10: [3108, 3106, 3228]}\nFifth Cluster: {1: [5234, 5235, 5213, 5254], 2: [5130, 5223, 5245, 5236], 3: [5205, 3212, 5220], 4: [5250, 5241, 5242]}\n"
     ]
    }
   ],
   "source": [
    "# View each cluster and their groupings\n",
    "print(f'First Cluster: {first_cluster}')\n",
    "print(f'Second Cluster: {second_cluster}')\n",
    "print(f'Third Cluster: {third_cluster}')\n",
    "print(f'Fourth Cluster: {fourth_cluster}')\n",
    "print(f'Fifth Cluster: {fifth_cluster}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing edge cases\n",
    "remainder_0 = first[3:]\n",
    "remainder_1 = first[2:]\n",
    "remainder_2 = first[1:]\n",
    "remainder_3 = first\n",
    "small_num_9 = first[-9:]\n",
    "small_num_5 = first[-5:]\n",
    "small_num_4 = first[-4:]\n",
    "small_num_3 = first[-3:]\n",
    "small_num_2 = first[-2:]\n",
    "small_num_1 = first[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: [5102]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "clust_dict = group_4(small_num_1)\n",
    "clust_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Sanity check - each story from the cluster was grouped\n",
    "unique = set()\n",
    "\n",
    "for inner_list in clust_dict.values():\n",
    "    for item in inner_list:\n",
    "        unique.add(item)\n",
    "    \n",
    "len(unique) == len(first)"
   ]
  },
  {
   "source": [
    "## KNN\n",
    "- Pull a random story, find the three nearest stories to create a group\n",
    "- Drop the stories that you have already grouped\n",
    "- TODO: Deal with the remainder problem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in function that continues until the remainder problem\n",
    "# Refit the data after you drop the grouped stories \n",
    "    # - otherwise it could suggest a story that we have already grouped and dropped\n",
    "\n",
    "def group_nn(df):\n",
    "    '''\n",
    "    Function creates groups of four from the input df by using Nearest Neighbors\n",
    "    Pulls one user, finds the three most similar users in the cohort to form the group\n",
    "    When there is a remainder of users not evenly divisable by 4, it will duplicate and entries, and have a couple of players play twice\n",
    "\n",
    "        Input: df to be grouped with the ID column first with ID being Integers\n",
    "        Output: dictionary of groupings {group ID #: list of story_id's}\n",
    "    '''\n",
    "    # Empty dictionary to store the groupings\n",
    "    groups = {}\n",
    "\n",
    "    # Instantiate scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Pull out features\n",
    "    features = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "    # Scale data\n",
    "    norm_x = scaler.fit_transform(features)\n",
    "\n",
    "    # Turn into df\n",
    "    df_norm_x = pd.DataFrame(norm_x)\n",
    "\n",
    "    # Instantiate model - groups of 4\n",
    "    nn = NearestNeighbors(n_neighbors=4, algorithm='kd_tree')\n",
    "\n",
    "    # Counter to use as key for groups in dictionary\n",
    "    counter = 1\n",
    "\n",
    "    # Grab a copy of the df before taking it apart to deal with the remainder problem\n",
    "    df_copy = df\n",
    "\n",
    "    # While loop that takes the top user and creates a group with the its three closest users\n",
    "    # Drops grouped users and continues until there are less than 12 users left to group\n",
    "    # Remainder problem will be dealt with after the while loop runs\n",
    "    while len(df_norm_x) >4:\n",
    "        # Fit the nearest neighbors model\n",
    "        nn.fit(df_norm_x)\n",
    "\n",
    "        # Find nearest neighbors\n",
    "        array_1, array_2 = nn.kneighbors([df_norm_x.iloc[0].values])\n",
    "\n",
    "        # Put story_id list into groups dictionary\n",
    "        groups[counter] = [df[df.columns[0]][item] for item in array_2[0]]\n",
    "\n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "\n",
    "        # Drop the users you have already grouped\n",
    "        # From both df's that you are using\n",
    "        df_norm_x = df_norm_x.drop(array_2[0])\n",
    "        df = df.drop(array_2[0])\n",
    "\n",
    "        # Reset the index\n",
    "        # For both datasets that you are using\n",
    "        df_norm_x.reset_index(inplace= True, drop= True)\n",
    "        df.reset_index(inplace= True, drop= True)\n",
    "\n",
    "    # Drop the remainders from copy of df to find most similar\n",
    "    for i in range(len(df)):\n",
    "        df_copy = df_copy[df_copy[df_copy.columns[0]] != int(df.iloc[i][0])]\n",
    "\n",
    "    # Do preproccesing done above\n",
    "    df_copy.reset_index(inplace=True, drop=True)\n",
    "    features_copy = df_copy.drop(df.columns[0], axis=1)\n",
    "    norm_x_copy = scaler.fit_transform(features_copy)\n",
    "    df_norm_x_copy = pd.DataFrame(norm_x_copy)\n",
    "    \n",
    "    # Fit to KNN model\n",
    "    nn.fit(df_norm_x_copy)\n",
    "    \n",
    "    # TODO: Finish remainder problem, going to get it working with perfect numbers first\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{1: [3132, 3220, 3114, 5260],\n",
       " 2: [3104, 3103, 3223, 3116],\n",
       " 3: [3117, 3127, 3214, 3110],\n",
       " 4: [3102, 5263, 5125, 5113],\n",
       " 5: [3105, 5104, 5109, 5116],\n",
       " 6: [3129, 3243, 5112, 3234],\n",
       " 7: [3111, 5214, 3207, 3124],\n",
       " 8: [3118, 3215, 5123, 3128],\n",
       " 9: [3120, 3231, 3201, 3244],\n",
       " 10: [3121, 3202, 5233, 3107],\n",
       " 11: [3119, 3131, 3206, 3238],\n",
       " 12: [3126, 5101, 3241, 3208],\n",
       " 13: [3109, 5218, 3122, 5203],\n",
       " 14: [3106, 3228, 3205, 3108],\n",
       " 15: [3101, 5228, 3211, 3224],\n",
       " 16: [3130, 5106, 5224, 5227],\n",
       " 17: [3112, 5238, 5216, 5126],\n",
       " 18: [3115, 5251, 5237, 5114],\n",
       " 19: [3123, 5258, 5207, 3225],\n",
       " 20: [3125, 5120, 3236, 3222],\n",
       " 21: [3113, 3235, 5232, 3210],\n",
       " 22: [3245, 3218, 5264, 5132],\n",
       " 23: [3216, 5102, 5239, 5240],\n",
       " 24: [3229, 3226, 3240, 5110],\n",
       " 25: [3227, 5209, 5243, 5221],\n",
       " 26: [3221, 5115, 3246, 3237],\n",
       " 27: [3219, 3239, 5217, 5105],\n",
       " 28: [3217, 3213, 5210, 3247],\n",
       " 29: [3232, 5225, 5249, 5121],\n",
       " 30: [3204, 5246, 5255, 5202],\n",
       " 31: [3203, 5256, 5103, 3248],\n",
       " 32: [3212, 5242, 5245, 5220],\n",
       " 33: [3209, 3230, 5206, 5257],\n",
       " 34: [5254, 5130, 5236, 5223],\n",
       " 35: [5253, 5131, 5208, 5248],\n",
       " 36: [5262, 5261, 5259, 5204],\n",
       " 37: [5252, 5111, 5205, 5222],\n",
       " 38: [5230, 5244, 5122, 5215],\n",
       " 39: [5241, 5250, 5247, 5119],\n",
       " 40: [5213, 5235, 5234, 5219],\n",
       " 41: [5229, 5108, 5129, 5118]}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Group 167 stories from db\n",
    "nn_groups = group_nn(df)\n",
    "nn_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   story_id  story_length  avg_word_len  quotes_num  unique_words_num  \\\n",
       "0      3132          1375      5.092593           6               138   \n",
       "1      3104           903      4.961538           0               110   \n",
       "2      3103           750      5.000000           1                93   \n",
       "3      3117           439      4.877778           1                56   \n",
       "4      3102          1812      4.897297           0               193   \n",
       "\n",
       "   adj_num  squad_score  cluster  \n",
       "0       15    47.843668        0  \n",
       "1       12    32.839743        2  \n",
       "2       10    29.830446        2  \n",
       "3        3    17.120997        2  \n",
       "4       22    54.416686        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>story_id</th>\n      <th>story_length</th>\n      <th>avg_word_len</th>\n      <th>quotes_num</th>\n      <th>unique_words_num</th>\n      <th>adj_num</th>\n      <th>squad_score</th>\n      <th>cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3132</td>\n      <td>1375</td>\n      <td>5.092593</td>\n      <td>6</td>\n      <td>138</td>\n      <td>15</td>\n      <td>47.843668</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3104</td>\n      <td>903</td>\n      <td>4.961538</td>\n      <td>0</td>\n      <td>110</td>\n      <td>12</td>\n      <td>32.839743</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3103</td>\n      <td>750</td>\n      <td>5.000000</td>\n      <td>1</td>\n      <td>93</td>\n      <td>10</td>\n      <td>29.830446</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3117</td>\n      <td>439</td>\n      <td>4.877778</td>\n      <td>1</td>\n      <td>56</td>\n      <td>3</td>\n      <td>17.120997</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3102</td>\n      <td>1812</td>\n      <td>4.897297</td>\n      <td>0</td>\n      <td>193</td>\n      <td>22</td>\n      <td>54.416686</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Sanity check - each story from the cluster was grouped\n",
    "unique = set()\n",
    "\n",
    "for inner_list in nn_groups.values():\n",
    "    for item in inner_list:\n",
    "        unique.add(item)\n",
    "    \n",
    "len(unique) == len(df) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}